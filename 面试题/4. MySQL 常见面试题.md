## 1. 关系型数据库和非关系数据库分别是什么？有什么区别？

- 关系型数据库
关系型数据库(RDBMS)是==基于关系模型的数据库，使用表格结构来组织和存储数据==，==数据是以行和列的形式存诸，并且可以通过定义主键和外键来建立表之间的关系==。
关系型数据库的特点主要有以下几个:
  1. **统一数据结构**:数据以表格的形式存储，表格由行和列组成，每个列都有对应的数据类型，提供了规范和结构化的数据存储方式。
  2. **强一致性**:关系型数据库遵循 ACID(原子性、一致性、隔离性、持久性)原则，保证数据的一致性和事务的完整性。
  3. **数据完整性**:关系型数据库支持定义表之间的关联关系，通过主键和外键进行数据的完整性约束。
  4. **丰富的查询功能**:通过 SOL查询语言，可以进行复杂的关系查询和连接操作，支持多表查询、条件查询、聚合查询等。
  5. 关系型数据库的典型代表有:OracleDB、MySQL、SQLServer(Microsoft)、PostgreSOL、DB2(IBM)等。

- 非关系型数据库
  非关系型数据库，或称为 NoSQL(Not Only SQL)数据库，是一种不同于传统关系型数据库的数据库系统。它们不依赖于表格和关系模型，而是**采用各种不同的数据模型(如键值对、文档、列族、图等)来存储和管理数据，并且放宽了对数据一致性的要求。**
  非关系型数据库的特点主要有以下几个:
  1. **灵活的数据模型**:非关系型数据库可以根据应用的需求选择和定制适合的数据模型，例如键值对、文档、列族、图等，以满足不同场景和数据结构的存储需求。
  2. **高可扩展性**:非关系型数据库天生支持分布式计算和存储，可以方便地进行横向扩展，以应对大规模数据和高并发访问的需求。
  3. **高性能和可用性**:由于非关系型数据库放宽了对一致性的要求，可以进行异步写入和读写分离等优化，从而获得较好的性能和可用性。

非关系型数据库的典型代表有:MongoDB、Redis、HBase、Neo4i等。

关系型数据库 VS 非关系型数据库
它们的区别主要体现在以下几点:
1. **数据模型不同**:
   - 关系型数据库:基于关系模型，数据以表格的形式存储，每个表都有预定义的列和数据类型。表与表之间通过外键建立关系，形成一个相互关联的数据集合。
   - 非关系型数据库:不采用表格和关系模型，数据可以以各种形式存储，如键值对、文档、图形等
2. **数据结构不同**:
   - 关系型数据库:数据结构严格，需要预先定义好表结构和字段类型，数据修改通常需要遵循一定的规范和约束。
   - 非关系型数据库:数据结构灵活，无需预先定义严格的模式，可以根据需要随时添加或修改数据结构
3. **查询语言不同**:
   - 关系型数据库:通常使用 SQL(Structured Query Language)进行查询，支持复杂的查询条件、联接操作和聚合函数。
   - 非关系型数据库:查询语言因数据库类型而异，有些支持类似 SOL的查询语法(如 MongoDB 的 MongoDBQuery Language)，有些则使用特定的 API或 DSL(领域特定语言)。
4. **事务支持不同**:
   - 关系型数据库:通常支持 ACID(Atomicity, Consistency, Isolation,Durability)事务特性，保证数据的一致性和完整性。
   - 非关系型数据库:事务支持程度因数据库类型而异，只有少量的 NOSQL 数据库可能只提供部分 ACID 特性，或者采用不同的一致性模型(如最终一致性)。
5. **扩展性与性能不同**：
   - 关系型数据库:传统的关系型数据库在水平扩展方面可能存在挑战，通常通过垂直扩展(增加单台服务器的硬件资源)来提高性能。
   - 非关系型数据库:设计上通常更易于水平扩展，通过添加更多服务器来分散数据和负载，以应对大规模数据和高并发访问。
6. **应用场景不同**：
    - 关系型数据库:适用于需要高度一致性和复杂查询的场景，如金融交易、企业级应用和内容管理系统等
   - 非关系型数据库:适用于海量数据存储、日志系统、大数据分析、实时处理、Web 应用和移动应用等领域尤其在处理半结构化和非结构化数据时具有优势。
## 2. 说一下数据库的三范式? 
>不可分割
>非主键必须完全依赖主键（学生-课程-学分  学分依赖课程 不可以）
>传递依赖（学生-院系-院系电话）


## 3. 说一说一条更新SQL的执行过程? 用到了哪些日志？
>1. 请求 2.解析 3.加锁和查询 4.undo log 5.数据更新内存 6.redo log 7.flush和sync 8.事务提交并redo log

在 MySQL 中，一条更新 SQL 语句执行的过程通常包括以下主要步骤:
1. **客户端发送请求**:客户端应用程序(如数据库连接器或应用程序)构建一条 UPDATE SQL语句，并将其发送到 MySQL 服务器端。
2. **查询解析和优化**:MySQL服务器接收到请求后，先进行语法解析 ->再经过查询优化器 ->生成执行计划。
3. **加锁和数据读取**:根据执行计划，MySQL 需要对受影响的数据行进行加锁，以确保事务的隔离性和一致性。对于可重复读和读已提交隔离级别，InnoDB 使用 Next-Key Locking(一种行锁机制)来防止幻读。加锁后,MySQL 从磁盘或内存中读取需要更新的数据行。
4. **Undo Log 记录**:在更新数据之前，InnoD 会为每一行被修改的数据创建一个 Undo Log 条目，记录原始数据的备份。这用于在事务回滚时能够恢复数据到更新前的状态。
5. **数据更新到内存**:MySQL 按照 UPDATE 语句指定的条件和新值，修改对应的数据行。更新后的数据首先存储在内存的 Buffer Pool 中。
6. **Redo Log 写入**:修改数据的同时，MySOL 会将更新操作记录到 Redo Log(重做日志)中。Redo Log 包含足够的信息来重新执行更新操作。
7. **Flush 和 Sync**:当 Redo Log 缓冲区达到一定大小或者经过一定时间后，MySOL 会将 Redo Log 缓冲区的内容刷新到磁盘上(称为 checkpoint)，并调用操作系统级别的 fsync()函数同步数据到磁盘，确保 Redo Log的持久性。
8. **事务提交并更新 Redo Log**:当所有更新操作完成并目 Redo Log 已经持久化到磁盘后，MySQL 可以提交事务，并将 Redo Log 的相应部分标记为已提交(commit 状态)。
9. **解锁和清理**:提交事务后，MySQL 会释放对数据行的锁定，允许其他事务访问这些数据。如果没有其他未提交事务依赖于 Undo Log，InnoDB 会在适当的时候清理 Undo Log，释放空间。
10. **结果返回**:MySOL将更新操作的结果(如受影响的行数)返回给客户端应用程序。

>PS:为什么更新操作操作需要这么多步骤?主要是为了提高效率的同时还要保证稳定性。

- 什么是 Undo Log?
Undo Log(回滚日志)是数据库用于实现事务原子性和回滚操作的日志。每当事务对数据库进行修改时，数据库系统都会记录一条对应的 Undo Log。这些日志记录了原始数据的备份以及修改前的状态。在事务提交之前，如果发生了错误或者事务被用户手动回滚，Undo Log 就会被用来撤销该事务的所有修改，恢复数据库到事务开始前的状态
- 什么是 Redo Log?
Redo Log(重做日志)是数据库用于保证事务持久性和 crash recovery(崩溃恢复)的日志。每当事务对数据库进行修改时，数据库系统也会记录一条对应的 Redo Log。这些日志记录了对数据库进行修改的具体操作和内容。在事务提交时，Redo Log 会被刷新到磁盘中。如果在事务提交后发生系统崩溃，数据库系统可以使用 Redo Log 来重新执行所有未完成的修改操作，确保事务的持久性，即使在系统崩溃后也能恢复到一致状态。
## 4. 联表查询的类型有哪些? 
>内连接、自连接、外连接

联表查询是指在数据库中同时查询多个表的数据的操作。根据查询的方式和目的，联表查询可以分为以下几种类型：

1. 内连接（INNER JOIN）：==内连接是最常见的联表查询类型，它会返回两个表中符合连接条件的记录==。

2. 外连接（OUTER JOIN）：外连接又分为左外连接（LEFT JOIN）、右外连接（RIGHT JOIN）和全外连接（FULL JOIN），它们==会返回符合连接条件的记录以及一个表中所有记录（左外连接或右外连接）或两个表中所有记录（全外连接）==。

3. 自连接（SELF JOIN）：自连接是指在同一张表中进行连接操作，==常用于需要比较同一表中不同记录之间的关系的情况==。


这些是常见的联表查询类型，根据具体的业务需求和数据结构，还可以进行更复杂的联表查询操作。

当涉及到数据库查询时，内连接、外连接和子连接是常用的连接方式。以下是它们的SQL语句和对应的使用场景举例：

1. 内连接（INNER JOIN）：
内连接是最常用的连接类型，它只返回两个表中符合连接条件的行。内连接的SQL语句如下所示：
```sql
SELECT *
FROM table1
INNER JOIN table2
ON table1.column = table2.column;
```
使用场景举例：假设有一个学生表和一个课程表，我们想要查询出选修了某门课程的学生信息，这时就可以使用内连接。

2. 外连接（OUTER JOIN）：
外连接用于返回符合连接条件的行以及未匹配的行。外连接分为左外连接（LEFT JOIN）、右外连接（RIGHT JOIN）和全外连接（FULL JOIN）。以下是左外连接的SQL语句示例：
```sql
SELECT *
FROM table1
LEFT JOIN table2
ON table1.column = table2.column;
```
使用场景举例：假设我们需要查询所有学生的信息，包括没有选修任何课程的学生，这时可以使用左外连接。

3. 子连接（SUBQUERY）：
子连接是指在查询中嵌套另一个查询，内部查询的结果会作为外部查询的条件之一。以下是子连接的SQL语句示例：
```sql
SELECT *
FROM table1
WHERE column IN (SELECT column FROM table2);
```
使用场景举例：假设我们需要查询选修了某门特定课程的学生信息，这时可以使用子连接来实现。

以上是内连接、外连接和子连接的SQL语句以及对应的使用场景举例，它们是在数据库查询中常用的连接方式。

## 5. MySQL 常用引擎有哪些? 
MySQL 的存储引擎是指 MySQL 数据库管理系统中用于处理数据存储和检索的组件。存储引擎负责实际存储和管理数据，以及提供对数据的访问和操作。

MySQL 提供了多个内置的存储引擎，每个存储引擎都有自己的特点和适用场景。不同的存储引擎可以为不同的应用场景提供不同的功能和性能。
MySOL 常用的存储引擎有以下几个:
1. InnoDB:MySQL(5.5+)的默认存储引擎，支持事务处理、行级锁定和物理外键约束。
   - 特性:提供良好的数据一致性、崩溃恢复和高并发性能。
   - 使用场景:适用于需要事务支持和多用户读写操作的应用场景。
2. MyISAM:MySQL 早期的默认存储引擎，不支持事务和行级锁定。
   - 特性:提供快速的读取速度和较小的数据存储文件。
   - 使用场景:适用于只读或读多写少的应用场景，不需要事务的场景，

3. MEMORY:将表的数据存储在内存中，提供极快的访问速度。
   - 特性:数据在服务器重启后会丢失。
   - 使用场景:适用于临时表、缓存表或者需要快速查询的小型表。

## 6. InnoDB 和 MyISAM 有什么区别?

>事务、锁粒度、外键、索引存储

InnoDB 和 MyISAM 是 MySQL 数据库中两种常见的存储引擎，它们有以下几点区别：

1. **事务支持**：InnoDB 支持事务处理，可以实现事务的原子性、一致性、隔离性和持久性（ACID特性），而 MyISAM 不支持事务处理。

2. **行级锁定**：InnoDB 支持行级锁定，可以提高并发性能，减少锁定冲突，而 MyISAM 只支持表级锁定，可能导致并发性能较差。

3. **外键约束**：InnoDB 支持外键约束，可以保证数据的完整性，而 MyISAM 不支持外键约束。

4. **性能特点**：一般情况下，InnoDB 在处理大量的并发读写操作时性能更好，而 MyISAM 在处理大量的读操作时性能较好。

5. **数据恢复**：InnoDB 支持崩溃恢复功能，可以在数据库崩溃后自动恢复数据，而 MyISAM 不支持崩溃恢复功能。

综上所述，选择使用 InnoDB 还是 MyISAM 取决于具体的应用场景和需求，如果需要事务支持、行级锁定、外键约束等功能，通常会选择 InnoDB；如果对性能要求较高且不需要事务支持等功能，可以考虑使用 MyISAM。

## 7. 为什么需要索引?创建索引时会锁表吗? DDL和DDM？
**索引主要是用于==提高数据检索速度的一种机制==**，通过索引数据库可以快速定位到目标数据的位置，而不需要遍历整个数据集，它就像书籍的目录部分，有它的存在，可以大大加速查询的效率。

创建索引会锁表吗?在 MySQL 5.6 之前，创建索引时会锁表，所以，在早期 MySQL 版本中一定要在线上慎用，因为创建索引时会导致其他会话阻塞(select 查询命令除外)。

但这个问题，在 MySQL 5.6.7版本中得到了改变，因为在 MySQL 5.6.7中引入了 Online DDL技术(在线 DDL技术)，它允许在创建索引时，不阻塞其他会话(所有的 DML 操作都可以一起并发执行)。

---
**什么是 DDL?**
DDL(Data Definition Language，数据库定义语言)):**用于定义和管理数据库的结构**，它主要包括以下语句:
- CREATE:用于创建数据库、表、索引、视图等对象。
- ALTER:用于修改数据库、表、索引、视图等已存在的对象的结构。
- DROP:用于删除数据库、表、索引、视图等对象
- TRUNCATE:用于删除表中的所有数据，但保留表的结构。
- RENAME:用于重命名数据库、表等对象。

**什么是 DML?**
DML(Data Manipulation Language，数据操作语言):用于查询和修改数据，它主要包括以下语句
- INSERT:用于向表中插入新的数据行
- UPDATE:用于更新表中已存在的数据行。
- DELETE:用于删除表中的数据行。
- SELECT:用于从表中检索数据。虽然 SELECT 主要用于查询，但某些包含数据修改的扩展 SQL 功能(如LIMIT、ORDER BY、GROUP BY 等)也属于 DML 的范畴。

**什么是 Online DDL?**
Online DDl (Online Data Definition Language，在线数据定义语言)==是指在数据库运行期间执行对表结构或其他数据库对象的更改操作，而不需要中断或阻塞其他正在进行的事务和查询==。
Online DDL 官方介绍档：
https://dev.mysql.com/doc/refman/8.0/en/innodb-online-ddl-operations.htmOnline 

DDL 操作定义如下:
![在这里插入图片描述](https://gitee.com/zdawdaw/img/raw/master/202409040831097.png)

## 8. 索引的分类有哪些？


**① 字段特性分类**
- **主键索引**：一张表只能有一个主键索引，不允许重复、不允许为 NULL。
- **唯一索引**：数据列不允许重复，允许为 NULL 值，一张表可有多个唯一索引，但是一个唯一索引通常只包含一列，例如，将身份证号码、卡号等作为唯一索引。
- **普通索引**：一张表可以创建多个普通索引，一个普通索引可以包含多个字段，允许数据重复，允许 NULL 值插
- **全文索引**：让搜索关键词更高效的一种索引。

**② 物理存储结构分类**
- **聚簇索引(聚集索引)**：一般是表中的主键索引，如果表中没有显示指定主键，则会选择表中的第一个不允许为 NULL 的唯一索引，如果还是没有的话，就采用 Innodb 存储引擎为每行数据内置的6字节 ROWID 作为聚簇索引或聚集索引。，每张表只有一个聚集索引，因为聚集索引的键值的逻辑顺序决定了表中相应行的物理顺序。聚集索引在精确查找和范围查找方面有良好的性能表现(相比于普通索引和全表扫描)，聚集索引就显得弥足珍贵，聚集索引选择还是要慎重的(一般不会让没有语义的自增 id 充当聚集索引)
- **非聚簇索引**：也叫做二级索引或辅助索引，该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同(非主键的那一列)，一个表中可以拥有多个非聚簇索引。

**③ 索引数量分类**
- **单列索引**:是指对表中的单个列创建的索引。它可以根据该列的值快速定位到对应的记录。单列索引适用于对单个列进行频繁的查询、排序和过滤操作的场景。例如，对于一个用户表，可以为用户 ID 列创建单列索引，以便快速根据用户 ID 进行查询。
- **联合索引**(也称为复合索引或组合索引):是指对表中的多个列创建的索引。它可以根据多个列的值进行排序和搜索。组合索引适用于需要同时根据多个列进行查询、排序和过滤操作的场景。例如，对于一个订单表，可以为订单日期和订单状态两列创建组合索引，以便快速根据日期和状态进行查询和排序。
## 9. 聚簇索引和非聚簇索引有什么区别?
>InnoDB下的聚簇索引和非聚簇索引：
>1. 聚簇索引：非叶子节点存储的是主键，叶子节点存储的是数据
>2. 非聚簇索引：非叶子节点存储的是二级索引，叶子节点存储的是主键
>
>MyISAM的非聚簇索引：叶子节点存储的是内存地址

聚簇索引的叶子节点(最底层节点)存储的是数据本身(行数据)，而非叶子节点(非最底层节点)存储的是索引键(通常是主键)，如下图所示:![在这里插入图片描述](https://gitee.com/zdawdaw/img/raw/master/202409040831099.png)非聚簇索引的叶子节点存储的是聚簇索引键(通常是主键)，而非数据本身，如下图所示:![在这里插入图片描述](https://gitee.com/zdawdaw/img/raw/master/202409040831100.png)
MyISAM 索引和上面非聚簇索引略有不同，它的叶子节点存储的是数据的内存地址(上面是主键)，如下图所示:![在这里插入图片描述](https://gitee.com/zdawdaw/img/raw/master/202409040831101.png)
但无论叶子节点存储的是聚簇索引键(主键索引)还是内存地址，它们都属于非聚簇索引(因为其节点存储的并不是数据本身)。

## 10. 聚簇索引是主键索引吗? 
聚簇索引大多数情况下等于主键索引，但如果表中没有(设置)主键索引的情况下，聚簇索引就等于其他索引类型

没有主键索引的情况下，聚簇索引等于哪种索引类型?
答:如果有主键索引时，那么**聚簇索引就等于主键索引**，如果没有主键索引，那么聚簇索引的诞生流程依次如下.1.无主键索引，则使用**非空唯一索引**:如果表中没有主键索引，那么 InnoDB 会使用第一个唯一索引(unique)，且此唯一索引设置了非空约束(not nul)，我们就使用它作为聚簇索引。
无任何满足索引，则生成隐藏聚簇索引:如果一张表既没有主键索引，又没有符合条件的唯一索引，那么InnoDB 会生成一个名为 GEN CLUST INDEX 的隐藏聚簇索引，这个隐藏的索引为 6 字节的长整数类型。
## 11. 索引的底层是如何实现的？
MySQL 索引的底层实现取决于存储引擎，但大部分的存储引擎的底层是通过 B+ 树实现的(Memory 是通过 Hash索引实现的）

以默认的存储引擎 InnoDB 为例，其底层是通过 B+ 树实现的，如下图所示：

![在这里插入图片描述](https://gitee.com/zdawdaw/img/raw/master/202409040831102.png)
B+ 树是一种自平衡的、多路搜索树，它的主要特征包含以下几点:
- 非叶子节点只存储键值和指向子节点的指针。
- 所有叶子节点(最底层的节点)都在同一个级别，并且包含所有的键值和对应的数据行指针或行数据。
- 所有叶子节点在同一层上，并通过双向链表连接，便于范围查询。

## 12. 为什么索引使用 B+ 树，而不是 B 树?
既然是做索引，那么查询性能就是第一优先考虑条件，而树结构比其他数据类型，例如:链表、队列、栈等查询效率都高，所以首先一定大方向是使用树结构。
>哈希索引的查询效率也很高，但没办法进行范围查询，所以也不合适作为大部分存储引擎的底层数据结构,

而树又分为二叉树搜索树和多又搜索树，而二叉搜索树的每个节点只有一个或两个子节点，这意味着查找一个元素可能需要多次 I/0 操作，而多路搜索树(如 B树和 B+ 树)的每个节点可以有多个子节点，这使得每个层级可以包含更多的数据，从而减少了查询过程中所需的 I/0 次数。而 I/0 次数是查询中最慢的操作，所以使用多又搜索树比又树更适合做索引。

在多叉树 B+ 树相比于 B 树有以下几点主要优势，所以它更适合做索引:
1. I0 次数更少(查询效率更高):B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比即存储索引又存储数据的 B树来说，B+ 树的非叶子节点可以存放更多的索引，因此在查询时I/0 次数更少，查询效率更高。
2. 范围查询性能更高:B+ 树叶子节点之间用链表连接了起来，有利于范围查询;而 B树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/0 操作，范围查询效率不如 B+ 树。
3. 插入和删除性能更好:B+ 树有大量的冗余节点(所有非叶子节点都是冗余索引)，这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化。

## 13. 什么是索引覆盖和索引下推?
索引覆盖和索引下推是优化数据库查询性能的两种常见技术。

1. **索引覆盖（Index Covering）**：==当一个查询的结果可以完全通过索引来获取，而不需要访问表中的实际数据行时，就称为索引覆盖==。这样可以减少IO操作，提高查询性能。

举例说明：
假设有一张表 `users`，包含字段 `id`、`name`、`age`，并且有一个索引 `idx_name` 包含 `name` 字段。如果我们执行以下查询：
```sql
SELECT id FROM users WHERE name = 'Alice';
```
如果索引 `idx_name` 能够覆盖这个查询，即索引中已经包含了 `id` 字段，那么数据库引擎就可以直接使用索引来获取结果，而不需要再去访问 `users` 表的实际数据行。

2. 索引下推（Index Pushdown）：索引下推是指数据库引擎在执行查询时，尽可能地利用索引来过滤数据，减少需要扫描的数据量，从而提高查询效率。

举例说明：
假设有一张表 `orders`，包含字段 `order_id`、`customer_id`、`order_date`，并且有一个联合索引 `idx_customer_order` 包含 `customer_id` 和 `order_date` 字段。如果我们执行以下查询：

```sql
SELECT order_id FROM orders WHERE customer_id = 123 AND order_date >= '2022-01-01';
```
如果数据库引擎支持索引下推，它会尝试将 `order_date >= '2022-01-01'` 这个条件下推到索引 `idx_customer_order` 上，先通过索引过滤出符合条件的数据行，然后再访问实际数据行获取 `order_id` 字段，从而减少需要扫描的数据量，提高查询效率。

通过索引覆盖和索引下推这两种技术，可以有效地优化数据库查询性能，降低系统的负载。

## 14. 什么是最左匹配原则? 为什么要遵循最左匹配原则? 
**什么是最左匹配原则?**
最左匹配原则是指在使用多列联合索引时，索引可以从左到右按顺序匹配查询条件，并提供有效的索引访问。最左匹配原则要求，查询中的条件必须按照联合索引的顺序，从最左边的列开始出现，并且不能跳过任何中间的列。

**为什么一定要遵循最左匹配原则?**
答：因为对于联合索引来说，它在构造 B+ 树的时候，会先按照左边的 key 进行排序，左边的 key 相同时，再依次按照右边的 key 排序，如下图所示:![在这里插入图片描述](https://gitee.com/zdawdaw/img/raw/master/202409040831104.png)
因此，在进行联合查询的时候，必须要遵守最左匹配原则，也就是需要从联合索引的最左边开始进行匹配，才能够准确的进行匹配。
## 15. 如何排查索引失效问题？（explain type key）
可以使用 SQL 查询计划，也就是 explain 来排查某个 SQL 是否使用了索引，以此来实现索引失效排查的问题。
explain 查询计划如下图所示:
![在这里插入图片描述](https://gitee.com/zdawdaw/img/raw/master/202409040831105.png)

查询结果中的字段有很多，我们关注的字段主要有以下两个:
1. type:表示查询时使用的访问方法或策略，描述了 MySQL 在执行查询时如何访问数据。常见的 type 值包括。 
   - ALL:全表扫描，表示 MySQL 将扫描整个表来找到匹配的行。
   - index:索引扫描，表示 MySQL 将通过索引进行扫描，但可能需要回表访问数据行
   - range:范围扫描，表示 MySQL 将使用索引的范围条件来定位匹配的行。
   - ref:使用非唯一索引进行查找，返回匹配某个值的所有行。
   - eq_ref:使用唯一索引进行查找，返回匹配某个值的单个行。
   - const:使用常量值进行查找，通常是通过主键或唯一索引进行精确匹配。
   - NULL:无效或未知的访问类型。
2. key:表示查询时使用的索引。如果查询使用了索引，key 字段将显示使用的索引名称;如果查询没有使用索引，key 字段将显示 NULL。

==也就说，当 explain 查询计划中的 key 不等于 NULL，并且 type 等于 index、range、ref、eq_ref、const 等时都表示此语句执行了索引查询，也就是索引并未失效。==
## 16. 索引失效的场景有哪些? 
索引失效的场景有以下几种:
1. **联合索引非最左匹配**：当使用联合索引时，未遵循最左匹配原则，则不能正常使用索引，也就是索引失效了
2. **不当模糊查询**：模糊查询 like 的常见用法有3种(只有第1种的会走索引，其他都会导致索引失效):
a. 模糊匹配后面任意字符:like'张%'
b. 模糊匹配前面任意字符:like'%张'
c. 模糊匹配前后任意字符:like'%张%'
3. **使用列运算**：如果索引列使用了运算，那么索引也会失效。
4. **使用函数**：查询列如果使用任意 MySQL 提供的函数就会导致索引失效。
5. **类型转换**：如果索引列存在类型转换，那么也不会走索引，比如某列为字符串类型，而查询的时候设置了 int类型的值就会导致索引失效。
6. **使用 is not null**：当在査询中使用了 is not null 也会导致索引失效，而 is null 则会正常触发索引的。
7. **使用 or 操作符**：当查询条件包含 or 连接的条件，索引也会失效。
## 17. 为什么需要事务？事务有哪些特性? 
事务(Transaction)是保证数据库==可靠性和稳定性的一种机制==。它是指数据库中的一组操作，==要么全部成功执行要么全部不执行==，不存在中间状态，事务提供了一种逻辑上的一致性和数据完整性的机制，以确保对数据库的更改是可靠性和可恢复性。

事务具有以下四个特性(ACID 特性):
1. **原子性(Atomicity)**：事务中的所有操作要么全部执行成功，要么全部失败回滚，不能只执行其中一部分操作。
2. **一致性(Consistency)**：事务执行前后，数据库的完整性约束没有被破坏，数据总是从一个一致性状态转移到另一个一致性状态。例如，如果一个事务要求将某个账户的金额从 A 转移到 B，那么无论事务是否成功，最终账户 A 和账户 B 的总金额应该保持不变。
3. **隔离性(Isolation)**：事务之间是相互隔离的，每个事务对其他事务的操作是透明的，一个事务的中间结果对其他事务是不可见的。隔离性可以防止并发执行的事务之间产生脏读、不可重复读和幻读等问题.
4. **持久性(Durability)**：事务完成后，对数据库的修改将永久保存在数据库中，即使系统故障也不会丢失。

事务四大特性是为了保证数据库的数据一致性和可靠性的，使得数据库在并发访问和故障恢复等复杂环境下，仍能保持数据的完整性。

这些特性对于许多应用场景，尤其是需要处理关键业务数据的应用，是非常重要的。例如在转账业务中，它分为两个关键性操作，首先是先扣除一个账户的钱，其次再给另一个账号增加钱。但是如果没有事务的保证，那么有可能第一次操作钱被扣了，但另一个账户钱没增加，那么这笔钱就凭空“消失”了。在这个实例中:
1. 原子性指的是要么转账两个账户都成功，要么一起失败，不存在执行一半的情况。
2. 一致性指的是转账之前两个账户的总额，等于转账之后的两个账号的总额(不考虑手续费的情况)，这个就是致性，不会存在总额不相等的情况。
3. 隔离性指的是正在执行的转账业务没有提交之前，其他事务能不能看到转账的详情，不同的隔离级别看到的数3.据是不一样的，例如最低的隔离级别读未提交，它是能读取转账执行一半未提交的数据的(但这个数据位脏数据，可能提交也可能回滚)。
4. 持久性指的是转账成功之后，数据就保存到磁盘了，即使重启 MySQL 服务，数据也不会丢失。

## 18. MySQL 如何保证事务四大特性?

事务的特性：原子性、持久性、隔离性、一致性
原子性：undo log，redo log
持久性：redo log
隔离性：事务的隔离级别
一致性：事务的隔离级别

MySQL 通过使用事务和锁机制来保证事务的四大特性，即原子性、一致性、隔离性和持久性。具体来说，MySQL 保证事务的四大特性的方式包括：

1. **原子性（Atomicity）**：MySQL 使用事务日志（Redo Log 和 Undo Log）来记录事务的操作，确保事务要么全部提交成功，要么全部回滚失败，从而保证事务的原子性。

2. **一致性（Consistency）**：MySQL 在执行事务过程中会根据事务的隔离级别（如读未提交、读已提交、可重复读、串行化）来控制事务之间的相互影响，以确保事务在执行过程中数据库始终保持一致性。

3. **隔离性（Isolation）**：MySQL 通过实现不同的事务隔禅级别（如读未提交、读已提交、可重复读、串行化）来控制事务之间的相互影响，避免并发执行的事务相互干扰，从而保证事务的隔离性。

4. **持久性（Durability）**：MySQL 使用事务日志（Redo Log）来记录事务的操作，确保事务提交后对数据的修改是持久的，即使系统发生故障也能够通过重放日志来恢复数据，从而保证事务的持久性。

综上所述，MySQL 通过事务日志和锁机制来保证事务的四大特性，确保数据库操作的安全性和一致性。
## 19. 事务有哪些隔离级别?
MySQL 中有事务隔离级别总共有以下 4 种:
1. 读未提交(Read Uncommitted):最低的隔离级别，事务中未提交的修改数据，可以被其他事务读取到。
   - 优点:并发性能最好，读取到的数据最新。
   - 缺点:存在脏读(Dirty Read)问题，即读取到未提交的数据，可能导致数据不一致性。
2. 读已提交(Read Committed):事务中未提交的修改数据，不会被其他事务读取到，此隔离级别看到的数2据，都是其他事务已经提交的数据。
   - 优点:避免了脏读的问题。
   - 缺点:存在不可重复读(Non-Repeatable Read)问题，即同一个事务中，不同时间读取到的数据可能不一样。
3. 可重复读(Repeatable Read):MySQL 默认的隔离级别，事务在开始时会创建一个视图，事务在其整个执行期间始终能看到这个视图中的数据，所以不会出现不可重复读的问题。但是，仍然可能发生”幻读”问题，即在同一个事务中，前后两次执行同样的范围查询可能会返回不同的行数，因为其他事务在这两次查询之间插入了新的行。
   - 优点:避免了不可重复读的问题，
   - 缺点:存在幻读(Phantom Read)问题，即在一个事务中，两次查询同一个范围的记录，但第二次查询却发现了新的记录。
4. 串行化(Serializable):最高的隔离级别，将所有的事务串行执行(一个执行完，另一个再执行)，保证了数据的完全隔离。
    - 优点:避免了幻读的问题。
    - 缺点:并发性能最差，可能导致大量的锁等待和死锁

MySQL 中的事务隔离级别就是为了解决脏读、不可重复读和幻读等问题的，这4种隔离级别与这 3个问题之间的对应关系如下:
![在这里插入图片描述](https://gitee.com/zdawdaw/img/raw/master/202409040831106.png)

## 20. 不可重复和幻读有什么区别?
- 不可重复读(Non-Repeatable Read)是指在一个事务中，多次执行相同的查询语句可能会得到不同的结果，因为其他并发事务在该事务正在进行时修改了数据
- 幻读(Phantom Read)是指在一个事务中，多次执行相同的查询语句可能会返回不同的结果集，因为其他并发事务在该事务正在进行时插入了新的数据行。

**不可重复读 VS 幻读**
不可重复读和幻读都是并发事务引起的读一致性问题，但两者关注的侧重点和解决方案不同。
侧重点不同:
1. 不可重复读关注的是一行数据的变化，它是指在同一个事务中，多次读取同一行数据的结果不一致。这是由。于其他并发事务对同一行数据做了修改(例如更新操作)，导致两次读取之间数据发生了变化。
2. 幻读关注的是范围数据的变化，它是指在同一个事务中，多次查询同一个范围的数据时，结果集的行数发生变化。这是由于其他并发事务在查询范围内插入了新的数据或者从中删除了数据，导致两次查询之间结果集中的行数发生了变化。
解决方案不同:
- 不可重复读通常使用行锁来解决，因为它关注的是一行数据
- 幻读通常使用间隙锁来解决，因为它关注的是范围数据
## 21. 为什么RR级别有幻读问题，却没有不可重读问题?
RR 级别(Repeatable Read，可重复读级别)中是没有不可重复读问题的，但存在幻读问题，这是因为，RR 级别通过使用多版本并发控制(MVCC)机制，==通过执行事务之前生成的快照Snapshot)视图==来解决了不可重复读的问题。在该级别下，读操作会读取事务开始时的快照数据，而不受其他并发事务的修改影响，从而保证了读操作的一致性，解决了不可重复读的问题。

然而，幻读问题不同于不可重复读问题，它发生在范围查询中，而不是在读取同一行数据时。**==也就是说快照机制能保证读取已存在记录==，但是幻读是新增或删除数据，这些数据之前没有快照，因此就无法使用快照机制来解决此问题了**，例如新增，之前是没有快照数据的，所以此时就会出现幻象行的数据(新增行的数据)，这就是为什么 RR级别可以解决不可重复读问题，但解决不了幻读的问题的主要原因了。
RR 级别可以通过快照机制，缓存并读取数据，而不受其他并发事务的影响，但幻读问题是新增或删除、是不能使用快照机制的，所以 RR 只能通过 MVCC 的快照机制解决不可重复读问题，但解决不了幻读问题。

## 22. 什么是 MVCC机制？

MVCC(Multi-Version Concurrency Control)是一种并发控制机制，用于解决数据库并发访问中，数据一致性问题。
>所谓的一致性问题，就是在并发事务执行时，应该看到哪些数据和不应该看到哪些数据。

在 MVCC 机制中，每个事务的读操作都能看到事务开始之前的一致性数据快照，而不受其他并发事务的修改的影响。==核心思想是通过创建多个数据版本，保持事务的一致性和隔离性。==

使用 MVCC 机制解决了 RR 隔离级别中，部分幻读问题，但又没把全部幻读问题都解决,。MVCC 解决了 RR 隔离级别中，快照读的幻读问题。多次查询快照读时，因为 RR 级别是复用 Read View(读视图)，所以没有幻读问题。
但 MVCC 解决不了 RR 隔离级别中，如果遇到快照读和当前读(读取当前最新的数据)中间发生过添加操作,那么 Read View 不能复用，就出现了幻读的问题。

> **快照读**:是指在一个事务中，读取的数据版本是在事务开始时已经存在的数据版本，而不是最新的数据版本。这种读取方式提供了事务在执行期间看到的数据视图的一致性，select 查询就是快照读。
>
> **当前读**:是指在事务中读取最新的数据版本，以下几种操作都是当前读 

>select ... for update;
>select ... lock in share mode;
>insert ...
>update ...
>delete ...
## 23. 说一下MVCC的实现原理?

MVCC 多版本并发控制，是用于解决并发事务数据一致性问题的机制。MVCC 主要是依靠以下两部分实现的:
1. **Undo Log 链**
2. **Read View(读视图或者叫一致性视图)**

**① Undo Log 链**
我们知道 Undo Log 主要是用于数据库中事务回滚的，但在 MVCC 机制中也发挥着重要的作用，那什么是 Undo Log 链呢?

>Undo Log 链是指在每个数据对象上维护的 Undo Log 记录链表。每张表都会有与之相对应的 Undo Log 链，用于记录修改前的数据信息(以方便数据进行回滚)。![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/618615585a84a4ef81aab7df2974effd.png)

**② Read View**
Read View(读视图)用于管理事务之间数据可见性的一种机制。Read View 在特定时刻为事务创建的一个快照该快照包含了在该时刻所有未提交事务的事务标识符，以及其他一些辅助信息。
在 Read View 中包含了以下 4 个主要的字段:
1. m ids:当前活跃的事务编号集合。
2. min trx id:最小活跃事务编号。
3. max trx id:预分配事务编号，当前最大事务编号+1。
4. creator trx id: ReadView 创建者的事务编号。
>RC 级别中，每次快照读都会生成一个全新的 Read View，而 RR 级别中同一个事务会复用一个 Read View。

**有了 Read View 和 Undo Log 链之后，并发事务在查询时就知道要读取那些版本的数据了。**
**① 判断方法**
- 判断方法是根据 Read View 中的4 个重要字段，先去 Undo Log 中最新的数据行进行比对，如果满足下面 ReadView 的判断条件，则返回当前行的数据，如果不满足则继续査找 Undo Log 的下一行数据，直到找到满足的条件的数据为止，如果查询完没有满足条件的数据，则返回 NULL。

**② 判断规则**
1. trx id==creator trx id:先将 Undo Log 最新数据行中的 trx id 和 ReadView 中的 creator trx id 进行对比，如果他们两个值相同，则说明是在同一个事务中执行，那么直接返回当前 Undo Log 的数据行即可，如果不相等，则继续下面流程。
2. trx id<min_trx id:如果 trx id 小于 min trx id，则说明在执行查询时，其他事务已经提交此行数据了那么直接返回此行数据即可，如果大于等于，则继续下面流程。
3. trx id>max trx id:如果 trx id 如果大于等于 max trx id，则说明该行数据比当前操作执行的晚，当前行数据不可见。
4. min_trx_id<=trx_id<max_trx_id:trx_id 在 min_trx_id 和 max_trx_id 之间还分为以下两种情况:
a. trx id 在 m_ids 中:说明事务尚未执行完，该行数据不可被访问。b. trx id 未在 m ids 中:说明事务已经执行完，可以返回该行数据。以上判断规则从 Undo Log 最新的行数据，逐行对比，直到找到匹配的数据，否则查询完未匹配上，则返回NULL.

## 24. 如何排查和优化慢 SQL? 
在 MySQL 中排查和优化慢 SQL 主要分为以下三步：
1. 开启 MySQL 慢日志:记录 MySQL 中执行比较慢的 SQL 语句,
2. 查看 SQL 执行计划:根据慢日志中的 SQL 查看执行计划，定位问题.。
3. 分析原因优化执行:根据 SQL 执行计划分析导致慢 SQL 的原因进行优化。

**① 开启 SQL 慢日志**
慢查询是 MySQL 中提供的一种慢查询日志，它用来记录在 MySQL 中响应时间超过阈值的语句，==具体指运行时间超过 long query time 值的 SQL，则会被记录到慢查询日志中==。慢日志参数 long query time 的默认值为 10，意思是运行 10 秒以上的语句。默认情况下，MySQL 数据库并不启动慢查询日志，需要我们手动来设置这个参数，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会给 MySQL 服务器带来一定的性能影响。慢查询日志支持将日志记录写入文件，也支持将日志记录写入数据库表。使用 `show variables like'%slow query log%`
来查询慢查询日志是否开启，执行效果如下图所示:![在这里插入图片描述](https://gitee.com/zdawdaw/img/raw/master/202409040831107.png)
**③ 根据原因优化 SQL**
根据上一步查询计划的结果，分析和优化 SOL，通常的优化手段有以下几个:
1. 正确使用索引:如果查询字段为创建索引，可以新建索引;如创建了索引但未正确使用，通过优化 SQL 正确使用索引来提高查询效率。
2. 添加缓存:通过多级缓存，例如分布式缓存 +本地缓存来优化查询效率。
3. 分库分表:单表行数超过 500 万行或者单表容量超过 2GB，推荐进行分库分表
4. 分布式数据库:使用大数据下性能更好的分布式数据库，例如 TiDB。
## 25. 如何进行分库分表? ★
- 分库分表就是将原本存储在一个数据库中的数据，分散到多个数据库或多个表中进行存储和查询。从而解决由于数据量过大而导致数据库性能降低的问题，将原来独立的数据库拆分成若干数据库组成，将数据大表拆分成若干数据表组成，使得单一数据库、单一数据表的数据量变小，从而达到提升数据性能的目的。

为什么需要分库分表?

答:分库分表的主要原因是为了提升查询性能，因为在单个数据库或数据表中，当数据量达到一定规模时，查询的性能就会明显的下降，因为此时进行查询需要搜索更多的数据或索引。又或者是在高并发场景下，如果有大量的读写请求时，会导致数据库连接数、锁竞争和磁盘 I/0 等资源达到瓶颈。而分库分表可以将请求压力分散到多个数据库或表中，降低单个数据库的并发压力，从而提升整体的查询效率，分库分表主要分为以下两种实现方式:
1. 垂直分割:按照业务逻辑，将一个库分成多个库，或将一张表的字段分成多张表的小字段。
   - 垂直分库
   - 垂直分表
2. 水平分割:按照某种规则(例如哈希取模)，将所有平行分配到多个库，或多张表。
   - 水平分库
   - 水平分表

如下图所示:![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/74916999479e4c1dc8c99c1cc5f7708a.png)

 ①垂直分库
按照业务逻辑，将一个数据库分成多个数据库，例如以下示例:![在这里插入图片描述](https://gitee.com/zdawdaw/img/raw/master/202409040831108.png)
② 垂直分表
按照业务逻辑，将一张表中的字段，拆分成多张表的字段，如下图所示:![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/7c023dc163eb3178038171c5f11b1248.png)
③ 水平分库
按照某种规则(例如哈希取模)将数据分配到多个库中(它们拥有相同的字段和表结构)，如下图所示:![在这里插入图片描述](https://gitee.com/zdawdaw/img/raw/master/202409040831109.png)
④ 水平分表
将数据分配到多个表中(它们拥有相同的字段和表结构)，如下图所示:按照某种规则(例如哈希取模)，![在这里插入图片描述](https://gitee.com/zdawdaw/img/raw/master/202409040831110.png)
**水平分割的策略有哪些?**
垂直分割通常和业务有关，而水平分割则会讲究一些策略了，常见的水平分割的策略有以下两种:
- 哈希分割:使用哈希函数对主键进行计算，然后根据哈希值将数据分配到不同的库或表中。==它的优点是分割的数据相对比较均匀，但缺点是不支持范围查询和排序操作。==
- 范围分割:根据某个列的值范围将数据分配到不同的库或表中。例如，可以按照时间范围(如年份、月份)或’者数值范围 (如 ID 的区间)进行分割。==范围分割适用于那些数据具有自然顺序或时间序列特性的场景。==

## 26. 分库分表后如何生成全局主键ID?
分库分表后就不能使用自增 ID 来作为表的主键了(因为分库分表后自增 ID 会重复)，此时可以使用 UUID 或雪花 ID 来作为全局主键 ID。
**UUID**
UUID (Universally Unique Identifier)是一种全局唯一标识符，它保证在空间和时间上的唯一性。通常由 128 位的数字组成，采用 32 位的十六进制数表示，格式为 8-4-4-4-12 这样的 36 个字符(32 个字母数字字符和4个短横线)，例如 550e8400-e29b-41d4-a716-446655440000。UUID 在 Java 中的实现如下:
```java
import java.util.UUID;

public class UUIDExample {
    public static void main(String[] args) {
        // 生成一个随机的 UUID
        UUID uuid = UUID.randomUUID();
        System.out.println("随机生成的 UUID: " + uuid);

        // 根据指定的字符串生成 UUID
        String uuidStr = "550e8400-e29b-41d4-a716-446655440000";
        UUID uuidFromString = UUID.fromString(uuidStr);
        System.out.println("根据字符串生成的 UUID: " + uuidFromString);
    }
}
```

通过调用 `UUID.randomUUID()` 方法可以生成一个随机的 UUID，调用 `UUID.fromString(String uuidStr)` 方法可以根据指定的字符串生成一个 UUID。UUID 是一个 128 位的全局唯一标识符，通常用于标识实体的唯一性。

虽然 UUID 可以保证全局唯一，但并不推荐使用 UUID 来作为分库分表后的主键 ID，因为 UUID 有两个问题:
1. UUID 太长，且生成效率较低。
2. UUID 没有任何业务含义，不连续且没有任何顺序可言

**② 雪花ID**

==分布式环境==下高效地生成全局唯一的 ID，具有一定的有序性。雪花 ID 的结构如下所示(共 64 位):
雪花 ID(Snowflake ID)是一个用于分布式系统中生成唯- ID 的算法，由 Titter 公司提出。它的设计目标是在分布式环境下高效地生成全局唯一的 ID，具有一定的有序性。![在这里插入图片描述](https://gitee.com/zdawdaw/img/raw/master/202409040831111.png)
这四部分代表的含义:
1. 符号位:最高位是符号位，始终为 0，1 表示负数，0 表示正数，ID 都是正整数，所以固定为 0。
2. 时间戳部分:由 41 位组成，精确到毫秒级。可以使用该 41 位表示的时间戳来表示的时间可以使用 69 年
3. 节点 ID 部分:由 10 位组成，用于表示机器节点的唯一标识符。在同一毫秒内，不同的节点生成的 ID 会有所不同。
4. 序列号部分:由 12 位组成，用于标识同一毫秒内生成的不同 ID 序列。在同一毫秒内，可以生成 4096 个不同4的 ID。

以下是一个简单的 Java 版本的雪花算法实现示例：

```java
public class Snowflake {

    private final long workerId;
    private final long epoch = 1609459200000L; // 2021-01-01 00:00:00
    private long sequence = 0L;
    private final long workerIdBits = 5L;
    private final long maxWorkerId = -1L ^ (-1L << workerIdBits);
    private final long timestampShift = workerIdBits;
    private final long workerIdShift = 12L;
    private final long timestampBits = 41L;
    private final long sequenceMask = -1L ^ (-1L << 12);

    private long lastTimestamp = -1L;

    public Snowflake(long workerId) {
        if (workerId > maxWorkerId || workerId < 0) {
            throw new IllegalArgumentException(String.format("Worker ID must be between 0 and %d", maxWorkerId));
        }
        this.workerId = workerId;
    }

    public synchronized long nextId() {
        long timestamp = System.currentTimeMillis();

        if (timestamp < lastTimestamp) {
            throw new RuntimeException("Clock moved backwards. Refusing to generate id for " + (lastTimestamp - timestamp) + " milliseconds");
        }

        if (lastTimestamp == timestamp) {
            sequence = (sequence + 1) & sequenceMask;
            if (sequence == 0) {
                timestamp = tilNextMillis(lastTimestamp);
            }
        } else {
            sequence = 0L;
        }

        lastTimestamp = timestamp;

        return ((timestamp - epoch) << timestampShift) | (workerId << workerIdShift) | sequence;
    }

    private long tilNextMillis(long lastTimestamp) {
        long timestamp = System.currentTimeMillis();
        while (timestamp <= lastTimestamp) {
            timestamp = System.currentTimeMillis();
        }
        return timestamp;
    }

    public static void main(String[] args) {
        Snowflake snowflake = new Snowflake(1);

        for (int i = 0; i < 10; i++) {
            System.out.println(snowflake.nextId());
        }
    }
}
```

这个示例实现了一个简单的雪花算法，可以生成唯一的 ID。在 `main` 方法中创建了一个 `Snowflake` 实例，并调用 `nextId` 方法生成 10 个 ID。你可以根据自己的需求进行修改和扩展。
## 27. 雪花算法存在什么问题?如何解决这些问题?
虽然雪花算法是一种被广泛采用的分布式唯一ID 生成算法，但它也存在以下几个问题:
1. **时间回拨问题**:雪花算法生成的 ID 依赖于系统的时间戳，要求系统的时钟必须是单调递增的。如果系统的时钟发生回拨，可能导致生成的 ID 重复。时间回拨是指系统的时钟在某个时间点之后突然往回走(人为设置)，即出现了时间上的逆流情况。
2. **时钟回拨带来的可用性和性能问题**:由于时间依赖性，当系统时钟发生回拨时，雪花算法需要进行额外的处理，如等待系统时钟追上上一次生成 ID 的时间戳或抛出异常。这种处理会对算法的可用性和性能产生一定影响。
3. **节点 ID 依赖问题**:雪花算法需要为每个节点分配唯一的节点 ID 来保证生成的 ID 的全局唯一性。节点 ID 的分配需要有一定的管理和调度，特别是在动态扩容或缩容时，节点 ID 的管理可能较为复杂。

**如何解决时间回拨问题?**
百度 UidGenerator 框架中解决了时间回拨的问题，并且解决方案比较经典，所以咱们这里就来给大家分享一下百度 UidGenerator 是怎么解决时间回拨问题的?

UidGenerator 介绍:UidGenerator 是百度开源的一个分布式唯一ID 生成器，它是基于 Snowflake 算法的改进版本。与传统的 Snowflake 算法相比，UidGenerator 在高并发场景下具有更好的性能和可用性。它的实现源码在:https://github.com/baidu/uid-generator

UidGenerator 是这样解决时间回拨问题的:UidGenerator 的每个实例中，都维护一个本地时钟缓存，用于记录当前时间戳。这个本地时钟会定期与系统时钟进行同步，如果检测到系统时钟往前走了出现了时钟回拨)，则将本地时钟调整为系统时钟。

## 28. 如何选择分片键?
分片键(Sharding Key)也叫做分表键或分表字段，它是指在数据库分库分表场景中，==用于确定数据行应该存储在哪个分片中的字段==。

它是根据某种策略(如哈希、范围、列表等)对数据进行分区或分片的依据，通过分表键可以将一个大表的数据分散到多个较小的物理表上，以达到水平扩展数据库性能的目的。

分表键的选择是一个相对来说较为复杂的问题，它需要根据实际的业务场景来决定，我们在选择分表键的时候需要考虑的主要因素有以下几个:
1. **数据分布均匀性**(防止数据切斜问题发生):理想的分表键应能保证数据在各个分片之间均匀分布，避免出现热点数据，即大部分请求集中在少数几个分片上的情况。例如，如果用户 ID 是一个良好的候选分表键，则可以根据用户 ID 进行哈希后决定其所在的分片。
2. **减少跨库跨表查询**:通常选择那些在查询操作中经常作为过滤条件的字段作为分表键，这样可以尽可能地减少2跨分片查询的需求。比如，在订单系统中，如果按用户 ID 分表，则可以根据用户 ID 直接定位到相应的分片进行查询。
3. **使用冗余字段提高查询速度**:分库分表之后，最大的问题在于联表查询的复杂度和查询性能大幅提升了，所以3.在这种场景下，我们需要考虑在特殊场景下，使用冗余字段提高查询性能和减少查询的复杂度。甚至很多情况下，我们可以考虑基于 binlog 或 flink 等方式同步某个维度的查询冗余数据(加速查询速度，用空间换时间)。

**水平分库和数据库分片有什么区别?**
水平分库和数据库分片的概念和功能和类似，但有略微的不同。首先来说，水平分库和数据库分片都是用于将大数据库拆分成多个小数据库，但二者侧重点不同:
- 水平分库是一种将单一数据库中的数据按照一定规则分散到多个数据库中的技术。这种拆分方式主要基于行进行，每个数据库都包含原始数据库的一部分数据，但所有的数据库结构都是相同的。水平分库的主要目的是降低单台数据库服务器的负载，提高系统的并发处理能力和整体性能。它通常应用于数据量巨大、访问频繁的场景。
- 数据库分片则是一种更广泛的数据库优化策略，它不仅仅局限于水平分库，还包括垂直拆分等多种方式。数据分片通过某种特定条件，将存放在同一数据库中的数据分散存储到多个数据库或者将同一张表的数据存储在表结构相同的多张表上，达到分散单台设备负载的效果。数据分片的目的同样是提升数据库的性能和可扩展性但它提供了更多的灵活性和选择

## 29.  ★ 常见的分片算法有哪些?工作中使用了哪种分片算法?为什么?
在MySQL中，常见的分片算法包括：

1. 哈希分片算法：根据数据的某个字段的哈希值来确定数据存储在哪个分片中。
2. 范围分片算法：根据数据的某个字段的范围来确定数据存储在哪个分片中。
3. 列表分片算法：根据预先定义的列表来确定数据存储在哪个分片中。

在工作中选择使用哪种分片算法取决于具体的业务需求和数据特点。一般来说，哈希分片算法是比较常见的选择，因为它能够将数据均匀地分布到不同的分片中，避免了数据倾斜的问题。范围分片算法适合按照某个连续的范围进行查询的场景，而列表分片算法适合按照离散的值进行查询的场景。

在实际工作中，选择分片算法需要综合考虑数据量、查询方式、扩展性等因素。如果数据量较大且查询方式比较均匀分布，哈希分片算法是一个不错的选择。如果数据具有明显的范围特征，范围分片算法可能更适合。而如果数据具有离散的特征，列表分片算法可能更合适。

因此，选择分片算法需要根据具体的业务场景和需求来进行评估和选择。

## 30. 分库分表的工具有哪些?

分库分表之后，如何像操作单表一样操作这些数据库和数据表呢?这就使用到分库分表的工具和框架了，目前市面上分库分表的工具和框架主要有以下几个:
1、ShardingSphere:ShardingSphere 是一个功能丰富的开源分布式数据库中间件，提供了完整的分库分表解决1.方案。它支持主流关系型数据库(如 MySOL、Oracle、SOL Server 等)，提供了分片、分布式事务、读写分离、数据治理等功能。ShardingSphere 具有灵活的配置和扩展性，支持多种分片策略，使用简单方便，项日地址:https://shardingsphere.apache.org
2、MyCAT:MyCAT(MySOL Clustering and Advancement Toolkit)是一个开源的分布式数据库中间件，特别适2合于大规模的分库分表应用。它支持 MySOL 和 MycatSQL，提供了分片、读写分离、分布式事务等功能。MyCAT 具有高性能、高可用性、可扩展性和易用性的特点，广泛应用于各种大型互联网和电商平台，项目地址:https://github.com/MyCATApache/Mycat2
3、TDDL:TDDL(Taobao Distributed Data Layer)是阿里巴巴开源的分库分表中间件。它为开发者提供了透明3的分库分表解决方案，可以将数据按照指定的规则分布到不同的数据库和表中。TDDL 支持 MVISAM 和InnoDB 引擎，提供了读写分离、动态扩容、数据迁移等功能，项日地址:https://github.com/alibaba/tb tddVitess:Vitess 是一个由 YouTube 开发和维护的分布式数据库集群中间件，支持 MVSOL作为后端存储系统,。
4、“Vitess 提供了水平拆分、弹性缩放、负载均衡、故障恢复等功能，可以在大规模的数据集和高并发访问场景下提供高性能和可扩展性，项目地址:https://vitess.io/zh/

## 31. 如何进行数据库调优？ ★
数据库调优主要有以下 4个手段:
1. 查询优化
2. 索引使用优化
3. 表字段优化
4. 分库分表
---
1. 查询优化
查询优化的主要实现有以下 3个:
   - 避免 SELECT *，只查询需要的字段。
   - ==小表驱动大表==，即小的数据集驱动大的数据集，比如，当 B表的数据集小于 A 表时，两表执行顺序是先查 B表，再査 A 表，査询语句:select*from A where id in(select id from B)。
   - 一些情况下，可以使用==连接(join)代替子查询，因为使用 join 时，MySOL 不会在内存中创建临时表==

2. 索引使用优化
   - 参考索引失效的场景，反向使用:目索引失效的场景有哪些?

3. 表字段优化
   - 使用简单的数据类型，int 要比 varchar 类型在 MySQL 处理简单 
   - 尽可能使用 not nul 定义字段，因为 null 占用 4 字节空间
   - 尽量少用 text/long text 类型，非用不可时最好考虑分表
   - 单表不要有太多字段，建议在 20 个字段以内。



1. 查询语句优化
   - 尽量避免使用 SELECT *，只查询需要的列。
   - 使用 JOIN 代替子查询，减少嵌套查询的层次,
   - 避免在 WHERE 子句中使用 LIKE'%value%'，这会导致全表扫描。
   - 合理使用 LIMIT 子句，限制查询结果的数量。
2. 索引优化
   - 合理使用索引:包括主键索引、唯一索引、普通索引和联合索引等。确保在经常用于查询条件的列上创建索引。
   - 避免过度索引:因为每个索引都会占用额外的存储空间，并可能影响写操作的性能。
3. 表结构优化
   - 垂直分表:将表中不常用的字段或大型字段(如 TEXT、BLOB)分离到单独的表中，减少主表的大小和 I/0 开销。
   - 水平分表:根据某种规则(如日期、地区等)将表中的数据分散到多个表中，每个表包含部分数据。这样可以提高查询效率，并降低单个表的锁竞争。
   - 归档旧数据:定期将不常用的旧数据归档到历史表中，减少主表的数据量，提高查询性能。
## 32. 什么是MySQL主从复制?它有什么优点? ★
MySQL主从复制是一种数据库复制技术，==用于将数据从一个MySQL数据库服务器（主服务器）复制到一个或多个其他MySQL数据库服务器（从服务器）==

主从复制优点
主从复制的主要优点有以下几个:
1. **可用性**:通过将主数据库的数据复制到一个或多个从数据库，可以在主数据库故障时快速切换到从数据库以实现系统的高可用性和容错能力，从而保证系统的持续可用性。
2. **提高整体性能和吞吐量**:通过将读请求分散到多个从服务器上进行处理，从而减轻了主服务器的负载压力，提高数据库系统的整体性能和吞吐量。主服务器主要负责写操作，而从服务器主要负责读操作，从而分担了主服务器的压力。
3. **数据备份和恢复**:通过主从同步，可以将主服务器上的数据异步复制到从服务器上，从而实现数据备份和灾难恢复的需求。在应对意外数据丢失、灾难恢复或误操作时，可以使用从服务器作为数据的备份源来进行数据恢复。
## 33. 如何实现主从复制? ★
好的,我来为您介绍一下MySQL主从复制的实现步骤:

1. 在主库上开启二进制日志:
   - 在MySQL配置文件my.cnf中添加以下配置:
```
     log-bin=mysql-bin
     server-id=1
```
   - 重启MySQL服务使配置生效。

2. 在从库上配置复制:
   - 在MySQL配置文件my.cnf中添加以下配置:
```
     server-id=2
     relay-log=relay-log
```
   - 重启MySQL服务使配置生效。

3. 在主库上创建复制账号:
   - 登录主库MySQL,执行以下SQL语句:
```sql
     CREATE USER 'repl'@'从库IP' IDENTIFIED BY '复制账号密码';
     GRANT REPLICATION SLAVE ON *.* TO 'repl'@'从库IP';
```

4. 在从库上配置复制:
   - 登录从库MySQL,执行以下SQL语句:
```sql
     CHANGE MASTER TO
     MASTER_HOST='主库IP',
     MASTER_USER='repl',
     MASTER_PASSWORD='复制账号密码',
     MASTER_LOG_FILE='mysql-bin.000001',
     MASTER_LOG_POS=0;
```
   - 启动从库复制进程:
```sql
     START SLAVE;
```

5. 检查复制状态:
   - 在从库上执行以下SQL语句查看复制状态:
```sql
     SHOW SLAVE STATUS\G
```
   - 如果Slave_IO_Running和Slave_SQL_Running都为Yes,则表示复制正常运行。

## 34. 说一下主从复制的实现原理?
MySQL 主从复制是一种将一个 MySQL 数据库实例（主库）的数据复制到一个或多个 MySQL 数据库实例（从库）的机制。通过这种方式，从库可以跟随主库的数据变化，并保持与主库一致。这种复制机制在读写分离、数据备份和故障转移等场景中非常有用。

MySQL 主从复制的实现原理包括以下几个主要步骤：

1. **主库（Master）的更新日志**：在主库中，所有数据的变更操作都会记录在二进制日志（binlog）中。这个日志包括了数据插入、更新和删除等操作以及事务信息。

2. **从库（Slave）的连接**：从库通过网络连接到主库，并请求获取从某个特定的日志文件和位置开始的更新。

3. **传输更新日志**：主库会将二进制日志中的变更记录通过网络发送给从库。这样，从库可以接收到主库的所有数据变更操作。

4. **从库的应用日志**：从库接收到主库传来的二进制日志后，会将其存储在中继日志（relay log）中。然后，从库的 SQL 线程会读取中继日志，并将其中的变更操作应用到从库的数据库中，从而实现数据同步。

5. **状态保持**：为了确保数据同步准确无误，从库需要时刻关注主库的二进制日志文件和位置。如果发生断连，从库会记住上次同步的位置，以便在重新连接后继续从那个位置接收数据。

通过这些步骤，从库可以实时或近实时地同步主库的所有数据变更。这种复制方式可以支持多种复制拓扑结构，包括单主多从、级联复制等。
## 35. BinLog有几种格式?
BinLog有两种格式，分别是Statement格式和Row格式。Statement格式是以SQL语句的形式记录数据库的更改操作，而Row格式则是记录每一行数据的变化情况。在MySQL中，可以通过设置binlog_format参数来指定使用哪种格式。

## 36. MySQL有几种主从复制模式? ★
MySQL 中主要有以下两种主从复制的模式，分别是异步复制和半同步复制。
- 异步复制:MySQL 主从复制中最常见和默认的模式。在异步复制模式中，主服务器将数据修改操作记录到二进制日志(Binary Log)中，并将日志传输给从服务器。从服务器接收到二进制日志后，会异步地应用这些日志进行数据复制。
   - 优点:它的优点是及时响应给使用者，==主服务器不会受到从服务器的影响而等待确认，可以提高主服务器的性能==。
   - 缺点:由于是异步复制，可能存在数据传输的延迟，且从服务器上的复制过程是不可靠的。==如果主服务器故障，尚未应用到从服务器的数据可能会丢失==。
2. 半同步复制:半同步复制是 MySQL 主从复制中的一种增强模式。在半同步复制模式中，主服务器将数据修改操作记录到二进制日志，并等待至少一个从服务器确认已接收到并应用了这些日志后才继续执行后续操作。
   - 优点:==可以提供更高的数据一致性和可靠性==，确保至少一个从服务器与主服务器保持同步。如果主服务器故障，已经确认接收并应用到从服务器的数据不会丢失。
   - 缺点:==由于半同步复制需要等待从服务器的确认，因此相对于异步复制，会增加一定的延迟，可能会影响主服务器的性能==。

如果对数据一致性和可靠性要求较高，可以考虑使用半同步复制;如果对延迟和主服务器性能要求较高，可以继续使用异步复制，根据实际需求调整复制模式。

# 一般面试题

## 1. MySQL中约束和索引有什么关系?
在MySQL中，约束（constraints）和索引（indexes）都是用来确保数据库数据完整性和提高查询效率的工具，但它们有不同的作用和用途。

1. 约束（Constraints）：
   - ==约束是一种规则，用于限制表中数据的类型、格式和完整性，确保数据的一致性和准确性==。
   - 常见的约束包括==主键约束（Primary Key Constraint）、唯一约束（Unique Constraint）、外键约束（Foreign Key Constraint）、检查约束（Check Constraint）等==。
   - 主键约束用于唯一标识表中的每一行数据，唯一约束用于确保列中的数据唯一性，外键约束用于保持表之间的关联性，检查约束用于限制列中数据的取值范围。

2. 索引（Indexes）：
   - 索引是一种==数据结构，用于加快数据库查询的速度，通过预先排序和存储数据的方式，可以快速定位和检索数据==。
   - 索引可以在表的一个或多个列上创建，用于加速查询和排序操作。
   - 索引可以大大提高查询性能，特别是在大型数据库中，对经常查询的列进行索引可以减少查询时间。

关系：
- 在某些情况下，==约束可以利用索引来实现其功能==。例如，==主键约约束和唯一约束通常会自动创建索引==来确保数据的唯一性和快速查找。外键约束也可以利用索引来加速关联表之间的查询。
- 因此，索引可以被视为一种用于支持约束实现的机制之一，但并不是所有的索引都与约束直接相关。
## 2. 说说InnoDB中的锁机制?
InnoDB是MySQL数据库中的一种存储引擎，其锁机制是保证数据并发访问安全的关键。在InnoDB中，锁机制主要分为两种类型：行级锁和表级锁。

1. **行级锁**：
   - InnoDB的默认锁类型是行级锁。这意味着在事务中，当对某行数据进行操作时，只会锁定该行，而不是整个表。这种锁定级别可以最大程度地提高并发性，允许多个事务同时修改表中不同的行，从而减少了锁冲突和等待时间。
   - 行级锁的实现方式可以是共享锁（Shared Lock）和排他锁（Exclusive Lock）。共享锁允许多个事务同时读取一行数据，而排他锁则只允许一个事务对一行数据进行写入操作。

2. **表级锁**：
   - 表级锁是对整个表进行锁定，它会阻止其他事务对整个表进行写入操作。在InnoDB中，表级锁是在需要对整个表进行操作时自动获取的，例如在对表进行重建或者使用ALTER TABLE语句时。
   - 表级锁通常是隐式获取的，而不需要显式的SQL语句进行锁定。

InnoDB的锁机制是为了保证数据的一致性和完整性，在并发访问情况下确保数据的正确性。通过合理的设计和使用锁机制，可以提高数据库的性能和并发处理能力，同时避免死锁和数据不一致等问题。

## 3. MySQL中如何实现乐观锁?

在 MySQL 中实现乐观锁通常涉及以下步骤：

1. **添加版本号列：** 在表中添加一个额外的列来保存版本号。这个版本号可以是一个整数或者是一个时间戳，用于跟踪每条记录的修改次数或者时间。

2. **读取数据：** 在事务开始时，读取需要更新的数据，包括版本号。

3. **在更新时检查版本号：** 在进行更新操作时，再次检查之前读取的数据的版本号是否与当前数据库中的版本号匹配。如果匹配，则说明在这个过程中没有其他事务对数据进行修改，可以继续更新。如果不匹配，则说明有其他事务修改了数据，需要根据业务逻辑决定如何处理，可以选择回滚事务或者重新尝试更新操作。

4. **更新数据并增加版本号：** 如果版本号匹配，将数据更新到数据库中，并且更新版本号。这个步骤需要在同一个事务中完成，以确保更新操作的原子性。

使用乐观锁的好处在于它不会对数据库进行加锁操作，因此在并发量较高的情况下可以提高性能。但是需要注意的是，在更新数据时需要确保事务的隔离级别设置正确，以避免数据不一致的问题。
## 4. 什么是意向锁?为什么需要意向锁?
MySQL中的意向锁（Intention Lock）是一种特殊的锁，用于在多粒度锁定时协调锁定的粒度。它是一种用于表级锁定的辅助锁。意向锁有两种类型：意向共享锁（IS）和意向排他锁（IX）。

意向共享锁（IS）指示事务打算在一个表或一个表的一部分上设置共享锁。意向排他锁（IX）指示事务打算在一个表或一个表的一部分上设置排他锁。在事务请求一个表或一个表的一部分上的锁之前，必须先获得适当的意向锁。

为什么需要意向锁呢？

1. 提高并发性能：意向锁可以帮助MySQL更有效地管理锁，减少因锁争用而造成的性能下降。通过在锁定级别上指示事务的意向，可以更好地管理锁定的粒度，从而减少锁定的竞争。

2. 锁定协调：在多粒度锁定时，意向锁可以帮助协调不同粒度的锁定。例如，如果一个事务请求一个表的排他锁，那么必须先获取该表的意向排他锁，而不是被其他事务阻塞在共享锁上。

3. 避免死锁：通过意向锁，MySQL可以更好地预测事务接下来可能请求的锁类型，从而减少死锁的可能性。如果一个事务已经持有了意向锁，那么其他事务就知道该表或该表的一部分可能会被锁定，从而可以相应地调整自己的锁请求，避免死锁的发生。

总的来说，意向锁在MySQL中扮演着重要的角色，帮助提高并发性能，优化锁定管理，并减少死锁的发生。

## 5. MySQL中有死锁吗?如何排查和解决死锁?

MySQL 中确实可能存在死锁问题。死锁指的是多个事务相互等待对方持有的资源而无法继续执行的情况。在数据库系统中，死锁通常发生在多个事务同时请求对同一组资源进行操作时。

要排查和解决死锁问题，可以采取以下方法：

1. **识别死锁**: 监控数据库系统，当发生死锁时，及时记录相关信息，如涉及的事务、资源等。

2. **分析死锁日志**: 当死锁发生时，查看数据库系统的日志，分析导致死锁的事务以及它们所持有的资源。

3. **优化事务设计**: 设计事务时，尽量减小事务持有资源的时间，减少死锁的可能性。可以尽量在事务中减少对资源的请求或持有时间，或者按照某种固定的顺序请求资源。

4. **设置适当的事务隔离级别**: 通过设置合适的事务隔离级别来减少死锁的可能性。根据应用的需求和业务场景，选择合适的隔离级别，如 READ COMMITTED、REPEATABLE READ 或 SERIALIZABLE。

5. **使用事务超时**: 在发生死锁时，可以设置事务超时机制，当事务执行时间超过预设的阈值时，自动回滚事务，以避免死锁。

6. **使用锁定和解锁命令**: 在事务中，合理地使用锁定和解锁命令，避免对资源的长时间持有。

7. **避免长时间事务**: 避免设计长时间运行的事务，尽量减小事务的范围和执行时间，以降低死锁的可能性。

8. **监控和优化数据库性能**: 定期监控数据库系统的性能，及时发现并解决可能导致死锁的性能瓶颈，优化数据库结构和查询语句，提高数据库系统的并发处理能力。

通过以上方法，可以有效地排查和解决 MySOL 数据库中可能出现的死锁问题，确保数据库系统的稳定运行。

## 6. MySQL中有哪些重要的日志?
MySQL中有几种重要的日志类型，包括：

1. 慢查询日志 (sow Query Log):记录执行时间超过指定阈值的查询语句。慢查询日志可以帮助识别性能较差的查询语句，以便进行优化。此日志默认关闭，需要手动开启。
2. 二进制日志(Binary Log):记录对数据库进行更改的所有操作，包括 INSERT、UPDATE、DELETE 等。二进制日志可以用于数据恢复、主从复制和数据同步等场景。二进制文件通常是开启的
3. 回滚日志(Undo Log):InnoDB 引擎中的日志，主要用于事务回滚和 MVCC 机制。
4. 重做日志(Redo Log):InnoDB 引擎中的日志，主要用于掉电或其他故障恢复的持久化日志


## 7. 如果我现在要把上面的表拆分成三张表(学生表、课程表、分数表)，这个表你会怎么设计?会有哪些字段?
### 你会在哪些字段上去创建索引?
表的关系:

1.一对一
2.一对多
3.多对多
- 学生表:包含的主要字段:主键+学生名+学号+姓名(不包含课程、分数)
- 课程表:一个学生可以有多个课程，一个课程又可以被多个同学选择->多对多的关系|包含的字段:主键+课程名+创建时间+修改时间+操作人|学生课程中间表包含的字段:中间表的ID、学生的ID、课程的ID.
- 分数表:包含字段:分数表主键+课程ID+学生ID+成绩

创建索引的原则:
多读少些的场最使用创建索引，例如姓名和成绩。
少读多写(添加、删除、修改)不建议创建索引。

## 8. 自增id用完了后会怎么样？

2.2 row id用完
如果表没有设置主键，InnoDB 会自动创建一个全局隐藏的 **row id**，其长度为6个字节，当 row id 达到上限后，它的执行流程和主键 ID 不同，它是再次归零，然后重新递增，如果出现相同的 row_id，后面的数据会覆盖之前的数据。